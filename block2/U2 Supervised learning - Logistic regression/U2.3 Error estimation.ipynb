{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# U2.3 Error estimation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Index\n",
    "\n",
    "1. Theoretical error of a classifier\n",
    "2. Error of the Bayes classifier\n",
    "3. Error estimation of a classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1 Theoretical error of a classifier\n",
    "\n",
    "**Purpose:** $\\;$ determine the error probability of a given classifier, $\\,c(\\boldsymbol{x})=\\operatorname{argmax}_c g_c(\\boldsymbol{x})$\n",
    "\n",
    "**A posteriori error:** $\\;$ error probability for a given $\\,\\boldsymbol{x}\\,$; one minus the probability of classifying $\\,\\boldsymbol{x}\\,$ correctly\n",
    "$$\\varepsilon(c(\\boldsymbol{x}))=1-P(c(\\boldsymbol{x})\\mid\\boldsymbol{x})$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(A priori) error with discrete $\\mathcal{X}$:** $\\;$ expected error probability according to the **unconditional probability** of $\\,\\boldsymbol{x}$\n",
    "$$\\varepsilon=\\mathbb{E}_{\\boldsymbol{x}}[\\varepsilon(c(\\boldsymbol{x}))]%\n",
    "=\\sum_{\\boldsymbol{x}\\in\\mathcal{X}}P(\\boldsymbol{x})\\,\\varepsilon(c(\\boldsymbol{x}))$$\n",
    "\n",
    "**Example:** $\\;\\mathcal{X}=\\{0,1\\}^2,\\,C=2$\n",
    "\n",
    "<div><table border-collapse: collapse><tr>\n",
    "<td style=\"border: none; vertical-align:top; padding:0; margin:0; text-align:center;\" width=500><center>\n",
    "\n",
    "<p style=\"text-align:center;\"><em>Theoretical knowledge</em></p>\n",
    "\n",
    "|$x_1$|$x_2$|$P(\\boldsymbol{x})$|$P(1\\vert\\boldsymbol{x})$|$P(2\\vert\\boldsymbol{x})$|\n",
    "|:-:|:-:|:-:|:-:|:-:|\n",
    "|$0$|$0$|$1/2$|$1$|$0$|\n",
    "|$0$|$1$|$1/4$|$3/4$|$1/4$|\n",
    "|$1$|$0$|$1/4$|$1/4$|$3/4$|\n",
    "|$1$|$1$|$0$|$0$|$1$|\n",
    "\n",
    "</center></td>\n",
    "<td style=\"border: none; vertical-align:top; padding:0; margin:0; text-align:center;\" width=500><center>\n",
    "\n",
    "<p style=\"text-align:center;\"><em>Theoretical error of a given classifier</em></p>\n",
    "\n",
    "|$x_1$|$x_2$|$c(\\boldsymbol{x})$|$\\varepsilon(c(\\boldsymbol{x}))$|$P(\\boldsymbol{x})\\varepsilon(c(\\boldsymbol{x}))$|\n",
    "|:-:|:-:|:-:|:-:|:-:|\n",
    "|$0$|$0$|$1$|$0$|$1/2 \\cdot 0 = 0$|\n",
    "|$0$|$1$|$1$|$1/4$|$1/4\\cdot 1/4  = 1/16$|\n",
    "|$1$|$0$|$1$|$3/4$|$1/4 \\cdot 3/4 = 3/16$|\n",
    "|$1$|$1$|$2$|$0$|$0 \\cdot 0 = 0$|\n",
    "\n",
    "$$\\varepsilon=1/16+3/16=1/4$$\n",
    "\n",
    "</center></td></tr></table></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(A priori) error with continuous $\\mathcal{X}$:** $\\;$ expected error probability according to the **unconditional probability density** of $\\,\\boldsymbol{x} $\n",
    "$$\\varepsilon=\\mathbb{E}_{\\boldsymbol{x}}[\\varepsilon(c(\\boldsymbol{x}))]%\n",
    "=\\int p(\\boldsymbol{x})\\,\\varepsilon(c(\\boldsymbol{x}))\\,d\\boldsymbol{x}$$\n",
    "\n",
    "**Example:** $\\quad\\mathcal{X}=\\mathbb{R}\\quad C=2\\quad c(x)=1$\n",
    "\n",
    "*Theoretical knowledge:* $\\quad p(x)=\\begin{cases}1/2&x\\in[-3/4,-1/4]\\\\1&x\\in [-1/4,1/4]\\\\ 1/2&x\\in [1/4, 3/4]\\end{cases}\\qquad P(c=1\\vert x)=\\begin{cases}1&x\\in [-3/4,-1/4 ]\\\\ 1/2&x\\in [-1/4,1/4]\\\\ 0&x\\in [1/4, 3/4]\\end{cases}$\n",
    "\n",
    "*Theoretical error of the given classifier:*\n",
    "$$\\varepsilon(c(x))=\\begin{cases}0&x\\in[-3/4,-1/4]\\\\1/2&x\\in[-1/4,1/4]\\\\1&x \\in[1/4, 3/4]\\end{cases}\n",
    "\\;\\to\\;\\varepsilon=\\int p(x)\\,\\varepsilon(c(x))\\,dx=\\int_{-1/4}^{1/4}1\\cdot\\frac{1 }{2}\\,dx+\\int_{1/4}^{3/4}\\frac{1}{2}\\cdot 1\\,dx=\\frac{1}{2}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2 Error of Bayes' classifier\n",
    "\n",
    "**Bayes' classifier or MAP decision rule (maximum a posteriori):** $\\quad c^*(\\boldsymbol{x})=\\operatorname*{argmax}_c\\; P(c\\mid\\boldsymbol{x})$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**A posteriori Bayes' error:** $\\quad\\varepsilon(c^*(\\boldsymbol{x}))=1-P(c^*(\\boldsymbol{x})\\mid\\boldsymbol{x}) =1-\\max_c P(c\\mid\\boldsymbol{x})$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(A priori) Bayes' error with $\\mathcal{X}$ discrete:** $\\quad\\varepsilon^*=\\mathbb{E}_{\\boldsymbol{x}}[\\varepsilon(c^*(\\boldsymbol{x}))]=\\sum_{\\boldsymbol{x}\\in\\mathcal{X}}P(\\boldsymbol{x})\\,\\varepsilon(c^*(\\boldsymbol{x}))$\n",
    "\n",
    "**Example (cont.):** $\\;\\mathcal{X}=\\{0,1\\}^2,\\,C=2$\n",
    "\n",
    "<div><table border-collapse: collapse><tr>\n",
    "<td style=\"border: none; vertical-align:top; padding:0; margin:0; text-align:center;\" width=500><center>\n",
    "\n",
    "<p style=\"text-align:center;\"><em>Theoretical knowledge</em></p>\n",
    "\n",
    "|$x_1$|$x_2$|$P(\\boldsymbol{x})$|$P(1\\vert\\boldsymbol{x})$|$P(2\\vert\\boldsymbol{x})$|\n",
    "|:-:|:-:|:-:|:-:|:-:|\n",
    "|$0$|$0$|$1/2$|$1$|$0$|\n",
    "|$0$|$1$|$1/4$|$3/4$|$1/4$|\n",
    "|$1$|$0$|$1/4$|$1/4$|$3/4$|\n",
    "|$1$|$1$|$0$|$0$|$1$|\n",
    "\n",
    "</center></td>\n",
    "<td style=\"border: none; vertical-align:top; padding:0; margin:0; text-align:center;\" width=500><center>\n",
    "\n",
    "<p style=\"text-align:center;\"><em>Bayes' error</em></p>\n",
    "\n",
    "|$x_1$|$x_2$|$c^*(\\boldsymbol{x})$|$\\varepsilon(c^*(\\boldsymbol{x}))$|$P(\\boldsymbol{x})\\varepsilon(c^*(\\boldsymbol{x}))$|\n",
    "|:-:|:-:|:-:|:-:|:-:|\n",
    "|$0$|$0$|$1$|$0$|$ 1/2 \\cdot 0 = 0$|\n",
    "|$0$|$1$|$1$|$1/4$|$1/4 \\cdot 1/4 = 1/16$|\n",
    "|$1$|$0$|$2$|$1/4$|$1/4 \\cdot 1/4 = 1/16$|\n",
    "|$1$|$1$|$2$|$0$|$0 \\cdot 0 = 0$|\n",
    "\n",
    "$$\\varepsilon^*=1/16+1/16=1/8$$\n",
    "\n",
    "</center></td></tr></table></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(A priori) Bayes' error with continuous $\\mathcal{X}$:** $\\quad\\varepsilon^*=\\mathbb{E}_{\\boldsymbol{x}}[\\varepsilon(c^*( \\boldsymbol{x}))]=\\int p(\\boldsymbol{x})\\,\\varepsilon(c^*(\\boldsymbol{x}))\\,d\\boldsymbol{x}$\n",
    "\n",
    "**Example (cont.):** $\\quad\\mathcal{X}=\\mathbb{R}\\quad C=2\\quad c^*(x)=1+\\mathbb{I}(1/4\\leq x\\leq 3/4)$\n",
    "\n",
    "*Theoretical knowledge:* $\\quad p(x)=\\begin{cases}1/2&x\\in[-3/4,-1/4]\\\\1&x\\in[-1/4,1/4]\\\\1/2&x\\in[1/4, 3/4]\\end{cases}\\qquad P(c=1\\mid x)=\\begin{cases}1&x\\in[-3/4,-1/4 ]\\\\1/2&x\\in[-1/4,1/4]\\\\0&x\\in[1/4, 3/4]\\end{cases}$\n",
    "\n",
    "*Bayes' error:* $\\displaystyle\\quad\\varepsilon(c^*(x))=\\begin{cases}0&x\\in[-3/4,-1/4]\\\\1/2&x\\in[- 1/4,1/4]\\\\0&x\\in[1/4, 3/4]\\end{cases}\\;\\to\\;\\varepsilon^*=\\int p(x)\\,\\varepsilon(c ^*(x))\\,dx=\\int_{-1/4}^{1/4}1\\cdot\\frac{1}{2}\\,dx=\\frac{1}{4}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3 Error estimation of a classifier\n",
    "\n",
    "**Impossibility to calculate the exact theoretical error:** $\\;$ since we do not have access to the theoretical knowledge\n",
    "\n",
    "**Error estimation by resubstitution:** $\\;$ consists of using the error rate computed on the training data\n",
    "\n",
    "**Resubtitution is optimistic:** $\\;$ a classifier that is limited to classifying the training data well (e.g. via memorization) will yield an error rate very close to zero, but it will perform poorly on future data, not seen in the training set\n",
    "\n",
    "**Error estimation by holdout:** $\\;$ consists of \"leaving out\" of the training set a part of the available data, which we call the **test set,** and compute the error rate on the test set\n",
    "\n",
    "**Holdout is (slightly) pessimistic:** $\\;$ since it estimates the error of a classifier trained with less data than available, and in general the error rate increases as the number of training samples is reduced\n",
    "\n",
    "**Normal approximation to the distribution of the holdout estimator:** $\\;$ if the number of test samples, $M$, is large, the holdout estimator can be considered a normal random variable whose mean is the theoretical error we want to estimate and the variance is inversely proportional to $M$\n",
    "$$\\hat{\\varepsilon}\\sim\\mathcal{N}\\left(\\varepsilon, \\frac{\\varepsilon(1-\\varepsilon)}{M}\\right)$$\n",
    "\n",
    "**95\\% Confidence Interval:** $\\;$ the normal approximation allows to provide the error estimation with a 95\\% confidence interval\n",
    "$$I_{95\\%}=[\\hat{\\varepsilon}-\\hat{r},\\hat{\\varepsilon}+\\hat{r}]%\n",
    "\\quad\\text{with radius}\\quad%\n",
    "\\hat{r}=1.96\\sqrt{\\frac{\\hat{\\varepsilon}(1-\\hat{\\varepsilon})}{M}}$$\n",
    "\n",
    "**Example:** $\\;$ if we have $100$ errors when classifying $M=2000$ test samples\n",
    "$$\\begin{align*}\n",
    "\\hat{\\varepsilon}&=\\frac{100}{2000}=0.05=5\\%\\\\\n",
    "\\hat{r}&=1.96\\sqrt{\\frac{0.05\\cdot 0.95}{2000}}=0.01\\\\\n",
    "I_{95\\%}&=[0.04, 0.06]=[4\\%, 6\\%]\n",
    "\\end{align*}$$"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
